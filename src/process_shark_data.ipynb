{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede64272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebcab9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets directory:\n",
      "/home/isekar/Documents/projects/NASA_SpaceApps_2025/Project/data\n",
      "Found sharks data? True\n"
     ]
    }
   ],
   "source": [
    "DIR_DATA = Path(os.path.dirname(os.path.abspath(''))).resolve() / \"data\"\n",
    "DIR_SOURCE = DIR_DATA / \"raw\"\n",
    "DIR_OUTPUT = DIR_DATA / \"processed\" / \"TOPP\"\n",
    "DIR_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "FILE_SHARKS = \"TRACKING-OF-PELAGIC-PREDATORS\"\n",
    "print(f\"Datasets directory:\\n{DIR_DATA}\")\n",
    "print(f\"Found sharks data? {Path(DIR_SOURCE / FILE_SHARKS).is_dir()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f531ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    r = 6371000 \n",
    "    return c * r\n",
    "\n",
    "def calculate_bearing(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dLon = lon2 - lon1\n",
    "    \n",
    "    x = sin(dLon) * cos(lat2)\n",
    "    y = cos(lat1) * sin(lat2) - sin(lat1) * cos(lat2) * cos(dLon)\n",
    "    \n",
    "    initial_bearing = atan2(x, y)\n",
    "    \n",
    "    initial_bearing = np.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "    return compass_bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f611008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date         0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "SharkID      0\n",
      "Species      0\n",
      "dtype: int64\n",
      "                        Date  Latitude  Longitude  SharkID     Species\n",
      "84902   01-Apr-2001 00:00:00    22.100   -152.750  1900004  GreatWhite\n",
      "84967   01-Apr-2001 12:00:00    22.200   -152.725  1900004  GreatWhite\n",
      "100029  01-Apr-2004 00:00:00    45.175   -129.425  1703006      Salmon\n",
      "45829   01-Apr-2004 00:00:00    38.100   -131.875  1903009  GreatWhite\n",
      "44241   01-Apr-2004 00:00:00    35.200   -152.525  1903007  GreatWhite\n",
      "...                      ...       ...        ...      ...         ...\n",
      "108801  31-Oct-2012 08:00:00    45.000   -124.975  1911038  GreatWhite\n",
      "92546   31-Oct-2012 12:00:00    25.125   -154.600  1911053  GreatWhite\n",
      "101734  31-Oct-2012 12:00:00    22.100   -136.125  1911027  GreatWhite\n",
      "108803  31-Oct-2012 12:00:00    45.250   -125.125  1911038  GreatWhite\n",
      "108805  31-Oct-2012 14:28:00    45.400   -125.225  1911038  GreatWhite\n",
      "\n",
      "[109136 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "white = pd.read_csv(DIR_SOURCE / FILE_SHARKS / \"GreatWhite.csv\")\n",
    "salmon = pd.read_csv(DIR_SOURCE / FILE_SHARKS / \"SalmonShark.csv\")\n",
    "\n",
    "white[\"Species\"] = \"GreatWhite\"\n",
    "salmon[\"Species\"] = \"Salmon\"\n",
    "\n",
    "sharks = pd.merge(left=white, right=salmon, how='outer').drop(\n",
    "    columns=[\"Unnamed: 0\", \n",
    "             \"Satellite SST\", \n",
    "             \"Observed SST\", \n",
    "             \"Observed Depth\", \n",
    "             \"Bathymetry Depth\"]).sort_values(by='Date')\n",
    "\n",
    "\n",
    "print(sharks.isna().sum())\n",
    "\n",
    "print(sharks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5145d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         distance_traveled  \\\n",
      "Species    SharkID time                 lon      lat                         \n",
      "GreatWhite 1900004 01-Apr-2001 12:00:00 -152.750 22.100       1.141369e+04   \n",
      "                   01-Dec-2000 00:00:00 -152.725 22.200       2.516905e+06   \n",
      "                   01-Dec-2000 01:36:50 -130.300 33.225       1.087473e+04   \n",
      "                   01-Dec-2000 06:00:00 -130.225 33.150       3.465991e+04   \n",
      "                   01-Dec-2000 08:00:00 -130.050 32.875       1.815638e+04   \n",
      "...                                                                    ...   \n",
      "Salmon     1707017 31-Oct-2007 00:00:00 -146.425 59.375       8.168946e+04   \n",
      "                   31-Oct-2007 02:02:48 -145.850 60.050       0.000000e+00   \n",
      "                   31-Oct-2007 02:59:48 -145.850 60.050       0.000000e+00   \n",
      "                   31-Oct-2007 12:00:00 -145.850 60.050       0.000000e+00   \n",
      "                   31-Oct-2007 15:15:48 -145.850 60.050       1.387835e+03   \n",
      "\n",
      "                                                                x         y  \n",
      "Species    SharkID time                 lon      lat                         \n",
      "GreatWhite 1900004 01-Apr-2001 12:00:00 -152.750 22.100  0.449317  0.893373  \n",
      "                   01-Dec-2000 00:00:00 -152.725 22.200 -0.510429  0.859920  \n",
      "                   01-Dec-2000 01:36:50 -130.300 33.225  0.968121 -0.250483  \n",
      "                   01-Dec-2000 06:00:00 -130.225 33.150  0.877390  0.479777  \n",
      "                   01-Dec-2000 08:00:00 -130.050 32.875  0.992818 -0.119636  \n",
      "...                                                           ...       ...  \n",
      "Salmon     1707017 31-Oct-2007 00:00:00 -146.425 59.375 -0.847004 -0.531587  \n",
      "                   31-Oct-2007 02:02:48 -145.850 60.050  0.000000  1.000000  \n",
      "                   31-Oct-2007 02:59:48 -145.850 60.050  0.000000  1.000000  \n",
      "                   31-Oct-2007 12:00:00 -145.850 60.050  0.000000  1.000000  \n",
      "                   31-Oct-2007 15:15:48 -145.850 60.050 -0.165374  0.986231  \n",
      "\n",
      "[107488 rows x 3 columns]\n",
      "distance_traveled    107488\n",
      "x                    107488\n",
      "y                    107488\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sharks = sharks.reset_index().drop_duplicates(\n",
    "    subset=[\"Species\", \"SharkID\", \"Date\"]\n",
    "    ).set_index(\n",
    "        [\"Species\", \"SharkID\", \"Date\"]\n",
    "        ).drop(\n",
    "            columns=['index']\n",
    "            ).sort_values(\n",
    "                ['Species', 'SharkID', 'Date'])\n",
    "\n",
    "sharks['prev_lat'] = sharks.groupby('SharkID')['Latitude'].shift(1)\n",
    "sharks['prev_lon'] = sharks.groupby('SharkID')['Longitude'].shift(1)\n",
    "\n",
    "mask = sharks['prev_lat'].notna()\n",
    "sharks.loc[mask, 'distance_traveled'] = sharks[mask].apply(\n",
    "    lambda row: haversine_distance(\n",
    "        row['prev_lon'], \n",
    "        row['prev_lat'], \n",
    "        row['Longitude'], \n",
    "        row['Latitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "sharks.loc[mask, 'orientation'] = sharks[mask].apply(\n",
    "    lambda row: calculate_bearing(\n",
    "        row['prev_lon'], \n",
    "        row['prev_lat'], \n",
    "        row['Longitude'], \n",
    "        row['Latitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "sharks = sharks.dropna(subset=['distance_traveled', 'orientation']).copy()\n",
    "sharks['x'] = sharks['orientation'].apply(sin)\n",
    "sharks['y'] = sharks['orientation'].apply(cos)\n",
    "\n",
    "sharks = sharks.drop(columns=[\"Longitude\", \"Latitude\", \"orientation\"])\n",
    "\n",
    "sharks = sharks.rename(\n",
    "    columns={\"prev_lat\": \"lat\", \n",
    "            \"prev_lon\": \"lon\"})\n",
    "\n",
    "sharks = sharks.rename_axis([\"Species\", \"SharkID\", \"time\"])\n",
    "\n",
    "sharks = sharks.set_index('lon', append=True)\n",
    "sharks = sharks.set_index('lat', append=True)\n",
    "\n",
    "sharks = sharks.sort_values(\n",
    "    ['Species', 'SharkID', \"time\", \"lon\", \"lat\"])\n",
    "\n",
    "sharks = sharks.astype(np.float32)\n",
    "\n",
    "print(sharks)\n",
    "\n",
    "print(sharks.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc1da617",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks = sharks.to_hdf(DIR_OUTPUT / \"SHARKS.h5\", key='sharks_df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpaceApps2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
